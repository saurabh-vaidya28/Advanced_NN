## Gradient Descent:<br>

-> It is a key optimization algorithm used to minimize the loss function in neural network during training.<br>
-> The goal is to adjust the weight and biases in the network to minimize the difference between predicted output and the actual target values (i.e., minimize the loss)<br>

### How Gradient Descent works?
1) Forward Bias:<br>
    - Input data is passed through the neural network.
    - The network produces an output based on its current weight and biases.

2) Compute loss:<br>
    - The difference between the predicted output and the actual value is computred using a loss function (e.g., MSE or Cross-Entropy loss)





