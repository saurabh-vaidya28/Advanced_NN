## 1. What is forward propagation in a neural network?
Answer: Forward propagation is the process through which input data passes through the network to generate an output. It involves computing the weighted sum of inputs at each layer, adding a bias, applying an activation function, and passing the result to the next layer. The final output layer produces the network's prediction.<br>
The steps are:<br>
- Compute the weighted sum of inputs.
- Add bias.
- Apply an activation function (like ReLU, Sigmoid, etc.).
- Repeat for all layers.
- Output the final prediction (in classification, usually through a sigmoid or softmax function).
<br>

## 2. Explain the formula for forward propagation in a neural network.<br>
Answer: In a neural network, forward propagation computes the activations layer by layer. The general formula for a single layer is:

<center>ğ‘<sup>[ğ‘™]</sup> = ğ‘Š<sup>[ğ‘™]</sup> ğ´<sup>[ğ‘™-1]</sup> + ğ‘<sup>[ğ‘™]</sup></center>

Where:
- Z<sup>[ğ‘™]</sup> is the weighted sum for the l-th layer.
- W<sup>[ğ‘™]</sup> is the weight matrix for the l-th layer.
- A<sup>[ğ‘™-1]</sup> is the activation output from the previous layer.
- b<sup>[ğ‘™]</sup> is the bias vector for the l-th layer.

Then, the activation function (e.g., ReLU, Sigmoid, or Tanh) is applied to Z<sup>[ğ‘™]</sup>:<br>
<center>ğ´<sup>[ğ‘™]</sup> = activation(ğ‘<sup>[ğ‘™]</sup>))</center><br>
This process repeats for all layers until the final output layer is reached.



