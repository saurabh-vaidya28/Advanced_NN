## 1. What is forward propagation in a neural network?
Answer: Forward propagation is the process through which input data passes through the network to generate an output. It involves computing the weighted sum of inputs at each layer, adding a bias, applying an activation function, and passing the result to the next layer. The final output layer produces the network's prediction.<br>
The steps are:<br>
- Compute the weighted sum of inputs.
- Add bias.
- Apply an activation function (like ReLU, Sigmoid, etc.).
- Repeat for all layers.
- Output the final prediction (in classification, usually through a sigmoid or softmax function).
<br>

## 2. Explain the formula for forward propagation in a neural network.<br>
Answer: In a neural network, forward propagation computes the activations layer by layer. The general formula for a single layer is:

ğ‘<sup>[ğ‘™]</sup> = ğ‘Š[ğ‘™] ğ´[ğ‘™âˆ’1] + ğ‘[ğ‘™]

Where:
- Z[l] is the weighted sum for the l-th layer.
- W[l] is the weight matrix for the l-th layer.
- A[lâˆ’1] is the activation output from the previous layer.
- b[l] is the bias vector for the l-th layer.

Then, the activation function (e.g., ReLU, Sigmoid, or Tanh) is applied to Z[l]:
ğ´[ğ‘™] = activation(ğ‘[ğ‘™]))
This process repeats for all layers until the final output layer is reached.



