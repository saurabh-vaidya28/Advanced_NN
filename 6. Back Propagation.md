### 1. What is backpropagation in a neural network?
Answer:
Backpropagation (short for "backward propagation of errors") is the algorithm used to minimize the loss function by adjusting the weights of the neural network through gradient descent. It works by computing the gradient of the loss function with respect to each weight and updating the weights to reduce the error between the predicted output and the true target.
Backpropagation consists of two phases:
- Forward Pass: The input is passed through the network to generate predictions.
- Backward Pass: The error is propagated back through the network to update the weights using gradient descent.









