### 1. What is the role of an optimizer in a neural network?
Answer: An optimizer’s role in a neural network is to update the network's weights during training by minimizing the loss function. The optimizer adjusts the weights based on the gradients (calculated via backpropagation), ensuring the network moves toward better performance with each iteration. By doing so, the optimizer helps the network learn from data and generalize well to unseen data.

The optimizer’s role is to find the best combination of weights and biases that leads to the most accurate predictions.

### Gradient Descent
Gradient Descent is a popular optimization method for training machine learning models. It works by iteratively adjusting the model parameters in the direction that minimizes the loss function.

Key Steps in Gradient Descent

1. Initialize parameters: Randomly initialize the model parameters.
2. Compute the gradient: Calculate the gradient (derivative) of the loss function with respect to the parameters.
3. Update parameters: Adjust the parameters by moving in the opposite direction of the gradient, scaled by the learning rate.
