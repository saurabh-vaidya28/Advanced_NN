A cost function (often referred to as a loss function) is a mathematical function that measures how well the neural network's predictions match the actual target values. In simple terms, it quantifies the "error" or difference between the predicted output of the network and the expected output (or true label).

The goal during training a neural network is to minimize the cost function, which improves the accuracy of the network's predictions.

Types of Cost Functions:
The type of cost function used depends on the problem you're trying to solve (e.g., classification or regression).

1. Mean Squared Error (MSE)
- Used for: Regression problems (where the output is continuous, like predicting a number).

- The function calculates the average squared difference between actual and predicted values. Minimizing the MSE leads to the network predicting values closer to the actual values.

2. Cross-Entropy Loss (Log Loss)
- Used for: Classification problems, particularly binary and multi-class classification.
- Binary Cross-Entropy (for binary classification):
- Categorical Cross-Entropy (for multi-class classification):








