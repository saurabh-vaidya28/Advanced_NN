### 1. What is an activation function in a neural network?
Answer:
- An activation function in a neural network is a mathematical function applied to the output of each neuron or node in a layer, transforming the input signal into an output signal.
- Its purpose is to introduce non-linearity into the network, enabling it to learn complex patterns and relationships in data.
- Without activation functions, the neural network would behave like a linear model, regardless of how many layers it has, and would be unable to solve non-linear problems.

### 2. Why are activation functions necessary in neural networks?
Answer:
Activation functions are necessary because they introduce non-linearity into the neural network. Without non-linearity, no matter how many layers are added to the network, it would essentially just be performing linear transformations (combinations of inputs and weights). Non-linearity enables the network to learn and approximate complex functions, making it capable of solving a wide range of tasks, such as classification, regression, and more.

### 3. Can you explain the difference between linear and non-linear activation functions?
Answer:
- Linear Activation Function: A linear activation function outputs a linear transformation of the input. It doesn't add any non-linearity, so no matter how many layers the network has, the output is still a linear combination of inputs. It is rarely used because it limits the network's ability to model complex data.

                            f(x)=ax+b
Example: f(x)=x.

- Non-linear Activation Functions: These functions allow the network to approximate more complex patterns and relationships in data. They introduce non-linearity into the network, which is crucial for tasks such as image recognition, language processing, etc.<br>
Example: Sigmoid, ReLU, Tanh, etc.




